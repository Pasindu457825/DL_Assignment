{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4680,"status":"ok","timestamp":1759859590919,"user":{"displayName":"Kumesha Wijesundara","userId":"00237240428166494044"},"user_tz":-330},"id":"DhA8Pcrig22P","outputId":"659c5cdb-cb23-4c56-a960-b8dfd767e141"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU Available: []\n"]}],"source":["import tensorflow as tf\n","print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20190,"status":"ok","timestamp":1759859611098,"user":{"displayName":"Kumesha Wijesundara","userId":"00237240428166494044"},"user_tz":-330},"id":"eJPZs-SphUJN","outputId":"3ceb14e1-7458-4225-9c5f-786462c88bd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":38},"id":"F8CREshyhg_r","outputId":"2d3d1da7-f9e2-451a-928f-967b37544434"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-bf332b82-7f35-46eb-bde7-dc8be80a89b0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-bf332b82-7f35-46eb-bde7-dc8be80a89b0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"'NoneType' object is not subscriptable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2535520808.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}],"source":["from google.colab import files\n","uploaded = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LmQjTXCqhsVw"},"outputs":[],"source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets list  # Test if it works"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RBVOLV46h6Lo"},"outputs":[],"source":["# Download the dataset\n","!kaggle datasets download -d sriramr/fruits-fresh-and-rotten-for-classification\n","\n","# Verify download\n","!ls -lh"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"udD6PTItiQ1n"},"outputs":[],"source":["import zipfile\n","import os\n","\n","# Extract\n","with zipfile.ZipFile('fruits-fresh-and-rotten-for-classification.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/fruit_dataset/')\n","\n","# Check structure\n","!ls -R /content/fruit_dataset/"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1roTdsInJsaWzd3e9t82Y-KRG5iZX3pJd"},"id":"vzWA2XOPizEW","executionInfo":{"status":"error","timestamp":1759905891091,"user_tz":-330,"elapsed":4047546,"user":{"displayName":"Kumesha Wijesundara","userId":"00237240428166494044"}},"outputId":"e33fbc73-8016-424c-9a9a-649453cc495d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# ==========================================\n","# FOOD FRESHNESS CLASSIFICATION USING RESNET50\n","# ==========================================\n","# Student: [Your Name]\n","# Part: Supervised Learning with ResNet50\n","# Dataset: Fruits Fresh and Rotten for Classification\n","# ==========================================\n","\n","# STEP 1: Import Required Libraries\n","# ==========================================\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","import os\n","from google.colab import drive\n","import zipfile\n","import cv2\n","from PIL import Image\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(f\"TensorFlow Version: {tf.__version__}\")\n","print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n","\n","# ==========================================\n","# STEP 2: Mount Google Drive and Setup Kaggle\n","# ==========================================\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Setup Kaggle API (Upload your kaggle.json to Colab)\n","# Instructions: Download kaggle.json from Kaggle Account Settings\n","from google.colab import files\n","print(\"Please upload your kaggle.json file:\")\n","uploaded = files.upload()\n","\n","# Configure Kaggle\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# ==========================================\n","# STEP 3: Download and Extract Dataset\n","# ==========================================\n","# Download dataset from Kaggle\n","!kaggle datasets download -d sriramr/fruits-fresh-and-rotten-for-classification\n","\n","# Extract dataset\n","zip_file = '/content/fruits-fresh-and-rotten-for-classification.zip'\n","extract_path = '/content/fruit_dataset/'\n","\n","with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Dataset extracted successfully!\")\n","print(\"Directory structure:\")\n","!ls -R /content/fruit_dataset/\n","\n","# ==========================================\n","# STEP 4: Data Exploration and Analysis\n","# ==========================================\n","\n","# Set dataset paths (adjust based on actual structure)\n","base_path = '/content/fruit_dataset/dataset/'\n","train_path = os.path.join(base_path, 'train')\n","test_path = os.path.join(base_path, 'test')\n","\n","# Function to count images in each category\n","def analyze_dataset(path):\n","    \"\"\"Analyze dataset structure and count images\"\"\"\n","    categories = {}\n","    if os.path.exists(path):\n","        for category in os.listdir(path):\n","            category_path = os.path.join(path, category)\n","            if os.path.isdir(category_path):\n","                num_images = len([f for f in os.listdir(category_path)\n","                                if f.endswith(('.jpg', '.jpeg', '.png'))])\n","                categories[category] = num_images\n","    return categories\n","\n","# Analyze train and test sets\n","train_categories = analyze_dataset(train_path)\n","test_categories = analyze_dataset(test_path)\n","\n","print(\"\\n=== DATASET ANALYSIS ===\")\n","print(f\"\\nTraining Set:\")\n","for cat, count in train_categories.items():\n","    print(f\"  {cat}: {count} images\")\n","\n","print(f\"\\nTest Set:\")\n","for cat, count in test_categories.items():\n","    print(f\"  {cat}: {count} images\")\n","\n","total_train = sum(train_categories.values())\n","total_test = sum(test_categories.values())\n","print(f\"\\nTotal Training Images: {total_train}\")\n","print(f\"Total Test Images: {total_test}\")\n","\n","# ==========================================\n","# STEP 5: Data Visualization\n","# ==========================================\n","\n","# Visualize class distribution\n","fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n","\n","# Training set distribution\n","axes[0].bar(train_categories.keys(), train_categories.values(), color='skyblue')\n","axes[0].set_title('Training Set Distribution', fontsize=14, fontweight='bold')\n","axes[0].set_xlabel('Categories')\n","axes[0].set_ylabel('Number of Images')\n","axes[0].tick_params(axis='x', rotation=45)\n","\n","# Test set distribution\n","axes[1].bar(test_categories.keys(), test_categories.values(), color='lightcoral')\n","axes[1].set_title('Test Set Distribution', fontsize=14, fontweight='bold')\n","axes[1].set_xlabel('Categories')\n","axes[1].set_ylabel('Number of Images')\n","axes[1].tick_params(axis='x', rotation=45)\n","\n","plt.tight_layout()\n","plt.savefig('/content/drive/MyDrive/class_distribution.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# Display sample images from each category\n","def display_sample_images(path, categories, samples_per_category=3):\n","    \"\"\"Display sample images from each category\"\"\"\n","    num_categories = len(categories)\n","    fig, axes = plt.subplots(num_categories, samples_per_category,\n","                            figsize=(15, 5*num_categories))\n","\n","    for idx, category in enumerate(categories):\n","        category_path = os.path.join(path, category)\n","        images = [f for f in os.listdir(category_path)\n","                 if f.endswith(('.jpg', '.jpeg', '.png'))][:samples_per_category]\n","\n","        for i, img_name in enumerate(images):\n","            img_path = os.path.join(category_path, img_name)\n","            img = Image.open(img_path)\n","\n","            if num_categories == 1:\n","                axes[i].imshow(img)\n","                axes[i].set_title(f'{category}')\n","                axes[i].axis('off')\n","            else:\n","                axes[idx, i].imshow(img)\n","                axes[idx, i].set_title(f'{category}')\n","                axes[idx, i].axis('off')\n","\n","    plt.tight_layout()\n","    plt.savefig('/content/drive/MyDrive/sample_images.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","print(\"\\n=== SAMPLE IMAGES ===\")\n","display_sample_images(train_path, list(train_categories.keys()))\n","\n","# ==========================================\n","# STEP 6: Image Analysis (Size, Color Distribution)\n","# ==========================================\n","\n","def analyze_image_properties(path, categories, num_samples=50):\n","    \"\"\"Analyze image properties like dimensions and color distribution\"\"\"\n","    widths, heights, channels = [], [], []\n","\n","    for category in categories:\n","        category_path = os.path.join(path, category)\n","        images = [f for f in os.listdir(category_path)\n","                 if f.endswith(('.jpg', '.jpeg', '.png'))][:num_samples]\n","\n","        for img_name in images:\n","            img_path = os.path.join(category_path, img_name)\n","            img = cv2.imread(img_path)\n","            if img is not None:\n","                h, w, c = img.shape\n","                heights.append(h)\n","                widths.append(w)\n","                channels.append(c)\n","\n","    return widths, heights, channels\n","\n","widths, heights, channels = analyze_image_properties(train_path, list(train_categories.keys()))\n","\n","print(\"\\n=== IMAGE PROPERTIES ANALYSIS ===\")\n","print(f\"Image Width - Mean: {np.mean(widths):.2f}, Std: {np.std(widths):.2f}\")\n","print(f\"Image Height - Mean: {np.mean(heights):.2f}, Std: {np.std(heights):.2f}\")\n","print(f\"Most common number of channels: {max(set(channels), key=channels.count)}\")\n","\n","# Visualize image dimensions\n","fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n","\n","axes[0].hist(widths, bins=30, color='blue', alpha=0.7)\n","axes[0].set_title('Image Width Distribution', fontsize=14, fontweight='bold')\n","axes[0].set_xlabel('Width (pixels)')\n","axes[0].set_ylabel('Frequency')\n","\n","axes[1].hist(heights, bins=30, color='green', alpha=0.7)\n","axes[1].set_title('Image Height Distribution', fontsize=14, fontweight='bold')\n","axes[1].set_xlabel('Height (pixels)')\n","axes[1].set_ylabel('Frequency')\n","\n","plt.tight_layout()\n","plt.savefig('/content/drive/MyDrive/image_dimensions.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# ==========================================\n","# STEP 7: Data Preprocessing and Augmentation\n","# ==========================================\n","\n","# Image dimensions for ResNet50\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","BATCH_SIZE = 32\n","NUM_CLASSES = len(train_categories)\n","\n","# Data Augmentation for Training\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    validation_split=0.2  # 20% for validation\n",")\n","\n","# Only rescaling for validation and test\n","test_datagen = ImageDataGenerator(\n","    rescale=1./255\n",")\n","\n","# Create data generators\n","train_generator = train_datagen.flow_from_directory(\n","    train_path,\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='training',\n","    shuffle=True\n",")\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    train_path,\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='validation',\n","    shuffle=False\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_path,\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle=False\n",")\n","\n","print(\"\\n=== DATA GENERATORS ===\")\n","print(f\"Training samples: {train_generator.samples}\")\n","print(f\"Validation samples: {validation_generator.samples}\")\n","print(f\"Test samples: {test_generator.samples}\")\n","print(f\"Class indices: {train_generator.class_indices}\")\n","\n","# ==========================================\n","# STEP 8: Build ResNet50 Model\n","# ==========================================\n","\n","def create_resnet50_model(num_classes, input_shape=(224, 224, 3)):\n","    \"\"\"\n","    Create ResNet50 model with transfer learning\n","    \"\"\"\n","    # Load pre-trained ResNet50 without top layers\n","    base_model = ResNet50(\n","        weights='imagenet',\n","        include_top=False,\n","        input_shape=input_shape\n","    )\n","\n","    # Freeze base model layers initially\n","    base_model.trainable = False\n","\n","    # Create new model\n","    model = models.Sequential([\n","        base_model,\n","        layers.GlobalAveragePooling2D(),\n","        layers.BatchNormalization(),\n","        layers.Dense(512, activation='relu'),\n","        layers.Dropout(0.5),\n","        layers.BatchNormalization(),\n","        layers.Dense(256, activation='relu'),\n","        layers.Dropout(0.3),\n","        layers.Dense(num_classes, activation='softmax')\n","    ])\n","\n","    return model, base_model\n","\n","# Create model\n","resnet_model, base_model = create_resnet50_model(NUM_CLASSES)\n","\n","# Display model architecture\n","print(\"\\n=== MODEL ARCHITECTURE ===\")\n","resnet_model.summary()\n","\n","# Save model architecture visualization\n","tf.keras.utils.plot_model(\n","    resnet_model,\n","    to_file='/content/drive/MyDrive/resnet50_architecture.png',\n","    show_shapes=True,\n","    show_layer_names=True,\n","    rankdir='TB',\n","    dpi=150\n",")\n","\n","# ==========================================\n","# STEP 9: Compile Model\n","# ==========================================\n","\n","# Compile model\n","initial_learning_rate = 0.001\n","\n","resnet_model.compile(\n","    optimizer=Adam(learning_rate=initial_learning_rate),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",")\n","\n","print(\"\\n=== MODEL COMPILED ===\")\n","print(f\"Optimizer: Adam\")\n","print(f\"Learning Rate: {initial_learning_rate}\")\n","print(f\"Loss Function: Categorical Crossentropy\")\n","\n","# ==========================================\n","# STEP 10: Setup Callbacks\n","# ==========================================\n","\n","# Early stopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    restore_best_weights=True,\n","    verbose=1\n",")\n","\n","# Reduce learning rate on plateau\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.2,\n","    patience=5,\n","    min_lr=1e-7,\n","    verbose=1\n",")\n","\n","# Model checkpoint\n","checkpoint_path = '/content/drive/MyDrive/resnet50_best_model.h5'\n","model_checkpoint = ModelCheckpoint(\n","    checkpoint_path,\n","    monitor='val_accuracy',\n","    save_best_only=True,\n","    verbose=1\n",")\n","\n","callbacks = [early_stopping, reduce_lr, model_checkpoint]\n","\n","# ==========================================\n","# STEP 11: Train Model (Phase 1 - Frozen Base)\n","# ==========================================\n","\n","print(\"\\n=== TRAINING PHASE 1: Frozen Base Model ===\")\n","EPOCHS_PHASE1 = 20\n","\n","history_phase1 = resnet_model.fit(\n","    train_generator,\n","    validation_data=validation_generator,\n","    epochs=EPOCHS_PHASE1,\n","    callbacks=callbacks,\n","    verbose=1\n",")\n","\n","# ==========================================\n","# STEP 12: Fine-tuning (Phase 2 - Unfrozen Base)\n","# ==========================================\n","\n","print(\"\\n=== TRAINING PHASE 2: Fine-tuning ===\")\n","\n","# Unfreeze the base model\n","base_model.trainable = True\n","\n","# Fine-tune from this layer onwards\n","fine_tune_at = 100\n","\n","# Freeze all layers before fine_tune_at\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable = False\n","\n","# Recompile with lower learning rate\n","resnet_model.compile(\n","    optimizer=Adam(learning_rate=1e-5),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",")\n","\n","EPOCHS_PHASE2 = 20\n","\n","history_phase2 = resnet_model.fit(\n","    train_generator,\n","    validation_data=validation_generator,\n","    epochs=EPOCHS_PHASE2,\n","    initial_epoch=history_phase1.epoch[-1],\n","    callbacks=callbacks,\n","    verbose=1\n",")\n","\n","# ==========================================\n","# STEP 13: Training History Visualization\n","# ==========================================\n","\n","def plot_training_history(history1, history2):\n","    \"\"\"Plot training and validation metrics\"\"\"\n","\n","    # Get precision/recall keys (handle both 'precision' and 'precision_1' naming)\n","    precision_key1 = 'precision' if 'precision' in history1.history else 'precision_1'\n","    recall_key1 = 'recall' if 'recall' in history1.history else 'recall_1'\n","    precision_key2 = 'precision' if 'precision' in history2.history else 'precision_1'\n","    recall_key2 = 'recall' if 'recall' in history2.history else 'recall_1'\n","\n","    # Combine histories\n","    acc = history1.history['accuracy'] + history2.history['accuracy']\n","    val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']\n","    loss = history1.history['loss'] + history2.history['loss']\n","    val_loss = history1.history['val_loss'] + history2.history['val_loss']\n","\n","    epochs_range = range(len(acc))\n","\n","    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n","\n","    # Accuracy\n","    axes[0, 0].plot(epochs_range, acc, label='Training Accuracy', linewidth=2)\n","    axes[0, 0].plot(epochs_range, val_acc, label='Validation Accuracy', linewidth=2)\n","    axes[0, 0].axvline(x=len(history1.history['accuracy']), color='r',\n","                       linestyle='--', label='Fine-tuning starts')\n","    axes[0, 0].set_title('Training and Validation Accuracy', fontweight='bold')\n","    axes[0, 0].set_xlabel('Epoch')\n","    axes[0, 0].set_ylabel('Accuracy')\n","    axes[0, 0].legend()\n","    axes[0, 0].grid(True, alpha=0.3)\n","\n","    # Loss\n","    axes[0, 1].plot(epochs_range, loss, label='Training Loss', linewidth=2)\n","    axes[0, 1].plot(epochs_range, val_loss, label='Validation Loss', linewidth=2)\n","    axes[0, 1].axvline(x=len(history1.history['loss']), color='r',\n","                       linestyle='--', label='Fine-tuning starts')\n","    axes[0, 1].set_title('Training and Validation Loss', fontweight='bold')\n","    axes[0, 1].set_xlabel('Epoch')\n","    axes[0, 1].set_ylabel('Loss')\n","    axes[0, 1].legend()\n","    axes[0, 1].grid(True, alpha=0.3)\n","\n","    # Precision\n","    precision = history1.history[precision_key1] + history2.history[precision_key2]\n","    val_precision = history1.history['val_' + precision_key1] + history2.history['val_' + precision_key2]\n","    axes[1, 0].plot(epochs_range, precision, label='Training Precision', linewidth=2)\n","    axes[1, 0].plot(epochs_range, val_precision, label='Validation Precision', linewidth=2)\n","    axes[1, 0].axvline(x=len(history1.history['accuracy']), color='r',\n","                       linestyle='--', label='Fine-tuning starts')\n","    axes[1, 0].set_title('Training and Validation Precision', fontweight='bold')\n","    axes[1, 0].set_xlabel('Epoch')\n","    axes[1, 0].set_ylabel('Precision')\n","    axes[1, 0].legend()\n","    axes[1, 0].grid(True, alpha=0.3)\n","\n","    # Recall\n","    recall = history1.history[recall_key1] + history2.history[recall_key2]\n","    val_recall = history1.history['val_' + recall_key1] + history2.history['val_' + recall_key2]\n","    axes[1, 1].plot(epochs_range, recall, label='Training Recall', linewidth=2)\n","    axes[1, 1].plot(epochs_range, val_recall, label='Validation Recall', linewidth=2)\n","    axes[1, 1].axvline(x=len(history1.history['accuracy']), color='r',\n","                       linestyle='--', label='Fine-tuning starts')\n","    axes[1, 1].set_title('Training and Validation Recall', fontweight='bold')\n","    axes[1, 1].set_xlabel('Epoch')\n","    axes[1, 1].set_ylabel('Recall')\n","    axes[1, 1].legend()\n","    axes[1, 1].grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig('/content/drive/MyDrive/training_history.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","plot_training_history(history_phase1, history_phase2)\n","\n","# ==========================================\n","# STEP 14: Model Evaluation on Test Set\n","# ==========================================\n","\n","print(\"\\n=== MODEL EVALUATION ===\")\n","\n","# Load best model\n","resnet_model.load_weights(checkpoint_path)\n","\n","# Evaluate on test set\n","test_loss, test_accuracy, test_precision, test_recall = resnet_model.evaluate(\n","    test_generator,\n","    verbose=1\n",")\n","\n","print(f\"\\nTest Accuracy: {test_accuracy*100:.2f}%\")\n","print(f\"Test Precision: {test_precision*100:.2f}%\")\n","print(f\"Test Recall: {test_recall*100:.2f}%\")\n","print(f\"Test Loss: {test_loss:.4f}\")\n","\n","# Calculate F1 Score\n","test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n","print(f\"Test F1-Score: {test_f1*100:.2f}%\")\n","\n","# ==========================================\n","# STEP 15: Predictions and Confusion Matrix\n","# ==========================================\n","\n","# Get predictions\n","test_generator.reset()\n","predictions = resnet_model.predict(test_generator, verbose=1)\n","predicted_classes = np.argmax(predictions, axis=1)\n","true_classes = test_generator.classes\n","class_labels = list(test_generator.class_indices.keys())\n","\n","# Confusion Matrix\n","cm = confusion_matrix(true_classes, predicted_classes)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=class_labels, yticklabels=class_labels)\n","plt.title('Confusion Matrix - ResNet50', fontsize=16, fontweight='bold')\n","plt.ylabel('True Label', fontsize=12)\n","plt.xlabel('Predicted Label', fontsize=12)\n","plt.tight_layout()\n","plt.savefig('/content/drive/MyDrive/confusion_matrix.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# ==========================================\n","# STEP 16: Classification Report\n","# ==========================================\n","\n","# Generate classification report\n","report = classification_report(true_classes, predicted_classes,\n","                              target_names=class_labels, digits=4)\n","print(\"\\n=== CLASSIFICATION REPORT ===\")\n","print(report)\n","\n","# Save report to file\n","with open('/content/drive/MyDrive/classification_report.txt', 'w') as f:\n","    f.write(\"=\" * 50 + \"\\n\")\n","    f.write(\"RESNET50 CLASSIFICATION REPORT\\n\")\n","    f.write(\"=\" * 50 + \"\\n\\n\")\n","    f.write(report)\n","    f.write(\"\\n\\n\" + \"=\" * 50 + \"\\n\")\n","    f.write(f\"Test Accuracy: {test_accuracy*100:.2f}%\\n\")\n","    f.write(f\"Test Precision: {test_precision*100:.2f}%\\n\")\n","    f.write(f\"Test Recall: {test_recall*100:.2f}%\\n\")\n","    f.write(f\"Test F1-Score: {test_f1*100:.2f}%\\n\")\n","    f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n","\n","# ==========================================\n","# STEP 17: Per-Class Performance Analysis\n","# ==========================================\n","\n","# Calculate per-class metrics\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","precision_per_class, recall_per_class, f1_per_class, support = precision_recall_fscore_support(\n","    true_classes, predicted_classes, labels=range(NUM_CLASSES)\n",")\n","\n","# Create DataFrame for better visualization\n","metrics_df = pd.DataFrame({\n","    'Class': class_labels,\n","    'Precision': precision_per_class,\n","    'Recall': recall_per_class,\n","    'F1-Score': f1_per_class,\n","    'Support': support\n","})\n","\n","print(\"\\n=== PER-CLASS PERFORMANCE ===\")\n","print(metrics_df.to_string(index=False))\n","\n","# Visualize per-class metrics\n","fig, ax = plt.subplots(figsize=(12, 6))\n","x = np.arange(len(class_labels))\n","width = 0.25\n","\n","bars1 = ax.bar(x - width, precision_per_class, width, label='Precision', alpha=0.8)\n","bars2 = ax.bar(x, recall_per_class, width, label='Recall', alpha=0.8)\n","bars3 = ax.bar(x + width, f1_per_class, width, label='F1-Score', alpha=0.8)\n","\n","ax.set_xlabel('Classes', fontweight='bold')\n","ax.set_ylabel('Scores', fontweight='bold')\n","ax.set_title('Per-Class Performance Metrics - ResNet50', fontsize=14, fontweight='bold')\n","ax.set_xticks(x)\n","ax.set_xticklabels(class_labels, rotation=45, ha='right')\n","ax.legend()\n","ax.grid(True, alpha=0.3, axis='y')\n","\n","plt.tight_layout()\n","plt.savefig('/content/drive/MyDrive/per_class_metrics.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# ==========================================\n","# STEP 18: Sample Predictions Visualization\n","# ==========================================\n","\n","def display_predictions(generator, model, num_samples=12):\n","    \"\"\"Display sample predictions with true and predicted labels\"\"\"\n","    generator.reset()\n","\n","    # Get a batch of images\n","    images, labels = next(generator)\n","    predictions = model.predict(images)\n","    predicted_classes = np.argmax(predictions, axis=1)\n","    true_classes = np.argmax(labels, axis=1)\n","\n","    # Get class names\n","    class_names = list(generator.class_indices.keys())\n","\n","    # Plot\n","    num_samples = min(num_samples, len(images))\n","    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n","    axes = axes.ravel()\n","\n","    for i in range(num_samples):\n","        axes[i].imshow(images[i])\n","\n","        true_label = class_names[true_classes[i]]\n","        pred_label = class_names[predicted_classes[i]]\n","        confidence = predictions[i][predicted_classes[i]] * 100\n","\n","        color = 'green' if true_classes[i] == predicted_classes[i] else 'red'\n","\n","        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%',\n","                         color=color, fontweight='bold')\n","        axes[i].axis('off')\n","\n","    plt.tight_layout()\n","    plt.savefig('/content/drive/MyDrive/sample_predictions.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","print(\"\\n=== SAMPLE PREDICTIONS ===\")\n","display_predictions(test_generator, resnet_model, num_samples=12)\n","\n","# ==========================================\n","# STEP 19: Save Final Model\n","# ==========================================\n","\n","# Save complete model\n","final_model_path = '/content/drive/MyDrive/resnet50_final_model.h5'\n","resnet_model.save(final_model_path)\n","print(f\"\\nFinal model saved to: {final_model_path}\")\n","\n","# Save model in SavedModel format (for deployment)\n","saved_model_path = '/content/drive/MyDrive/resnet50_savedmodel'\n","resnet_model.save(saved_model_path)\n","print(f\"SavedModel format saved to: {saved_model_path}\")\n","\n","# ==========================================\n","# STEP 20: Model Summary Statistics\n","# ==========================================\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"RESNET50 MODEL - FINAL SUMMARY\")\n","print(\"=\"*60)\n","print(f\"\\nDataset Statistics:\")\n","print(f\"  - Training Samples: {train_generator.samples}\")\n","print(f\"  - Validation Samples: {validation_generator.samples}\")\n","print(f\"  - Test Samples: {test_generator.samples}\")\n","print(f\"  - Number of Classes: {NUM_CLASSES}\")\n","print(f\"  - Classes: {', '.join(class_labels)}\")\n","\n","print(f\"\\nModel Architecture:\")\n","print(f\"  - Base Model: ResNet50 (ImageNet pre-trained)\")\n","print(f\"  - Input Shape: {IMG_HEIGHT}x{IMG_WIDTH}x3\")\n","print(f\"  - Total Parameters: {resnet_model.count_params():,}\")\n","print(f\"  - Trainable Parameters: {sum([tf.size(w).numpy() for w in resnet_model.trainable_weights]):,}\")\n","\n","print(f\"\\nTraining Configuration:\")\n","print(f\"  - Phase 1 Epochs: {EPOCHS_PHASE1}\")\n","print(f\"  - Phase 2 Epochs: {EPOCHS_PHASE2}\")\n","print(f\"  - Batch Size: {BATCH_SIZE}\")\n","print(f\"  - Initial Learning Rate: {initial_learning_rate}\")\n","print(f\"  - Fine-tuning Learning Rate: 1e-5\")\n","\n","print(f\"\\nFinal Test Performance:\")\n","print(f\"  - Accuracy: {test_accuracy*100:.2f}%\")\n","print(f\"  - Precision: {test_precision*100:.2f}%\")\n","print(f\"  - Recall: {test_recall*100:.2f}%\")\n","print(f\"  - F1-Score: {test_f1*100:.2f}%\")\n","print(f\"  - Loss: {test_loss:.4f}\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"All results saved to Google Drive!\")\n","print(\"=\"*60)\n","\n","# Save summary to file\n","with open('/content/drive/MyDrive/model_summary.txt', 'w') as f:\n","    f.write(\"=\"*60 + \"\\n\")\n","    f.write(\"RESNET50 MODEL - FINAL SUMMARY\\n\")\n","    f.write(\"=\"*60 + \"\\n\\n\")\n","\n","    f.write(\"Dataset Statistics:\\n\")\n","    f.write(f\"  - Training Samples: {train_generator.samples}\\n\")\n","    f.write(f\"  - Validation Samples: {validation_generator.samples}\\n\")\n","    f.write(f\"  - Test Samples: {test_generator.samples}\\n\")\n","    f.write(f\"  - Number of Classes: {NUM_CLASSES}\\n\")\n","    f.write(f\"  - Classes: {', '.join(class_labels)}\\n\\n\")\n","\n","    f.write(\"Model Architecture:\\n\")\n","    f.write(f\"  - Base Model: ResNet50 (ImageNet pre-trained)\\n\")\n","    f.write(f\"  - Input Shape: {IMG_HEIGHT}x{IMG_WIDTH}x3\\n\")\n","    f.write(f\"  - Total Parameters: {resnet_model.count_params():,}\\n\\n\")\n","\n","    f.write(\"Training Configuration:\\n\")\n","    f.write(f\"  - Phase 1 Epochs: {EPOCHS_PHASE1}\\n\")\n","    f.write(f\"  - Phase 2 Epochs: {EPOCHS_PHASE2}\\n\")\n","    f.write(f\"  - Batch Size: {BATCH_SIZE}\\n\")\n","    f.write(f\"  - Initial Learning Rate: {initial_learning_rate}\\n\")\n","    f.write(f\"  - Fine-tuning Learning Rate: 1e-5\\n\\n\")\n","\n","    f.write(\"Final Test Performance:\\n\")\n","    f.write(f\"  - Accuracy: {test_accuracy*100:.2f}%\\n\")\n","    f.write(f\"  - Precision: {test_precision*100:.2f}%\\n\")\n","    f.write(f\"  - Recall: {test_recall*100:.2f}%\\n\")\n","    f.write(f\"  - F1-Score: {test_f1*100:.2f}%\\n\")\n","    f.write(f\"  - Loss: {test_loss:.4f}\\n\")\n","\n","print(\"\\n‚úÖ ResNet50 implementation completed successfully!\")\n","print(\"üìÅ Check your Google Drive for all saved files and visualizations.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMdHwJqSfZccQP8/mcccCqE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}